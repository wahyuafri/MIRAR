# -*- coding: utf-8 -*-
"""Copy of Image Classification for Cataract.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDvOXDb6LcxoV8kXUvx10RXT7hUi44KY

#**12 - VULCAN**

#**Image Classification Using Machine Learning Model for Detecting Cataract to Patient Diagnose**

##1. Mount Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""##2. Load Depedencies"""

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
from matplotlib import pyplot as plt
# %matplotlib inline
import numpy as np
from sklearn.metrics import confusion_matrix , classification_report
import pandas as pd
import seaborn as sns
from os import listdir
from os.path import isfile, join

# Get filenames in list
mypath = "/content/drive/MyDrive/MBKM-CapstoneProject/images"
file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]
print(str(len(file_names)) + ' images loaded')

"""##3. Sift and GLCM Demo"""

plt.rcParams["figure.figsize"] = (10,10)
#reading image
img1 = cv2.imread(mypath+"/"+file_names[21])
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)

#keypoints
sift = cv2.xfeatures2d.SIFT_create()
keypoints_1, descriptors_1 = sift.detectAndCompute(gray1,None)

img_1 = cv2.drawKeypoints(gray1,keypoints_1,img1)
plt.imshow(img_1)
img1.shape
len(keypoints_1)

from skimage.feature import  graycomatrix, graycoprops
from skimage.measure import shannon_entropy
image = cv2.imread(mypath+"/"+file_names[21],0)
img_arr = np.array(image)
print(shannon_entropy(img_arr))
gCoMat = graycomatrix(img_arr, [1], [0],256,symmetric=True, normed=True) # Co-occurance matrix
contrast = graycoprops(gCoMat, prop='contrast')[0][0]
dissimilarity = graycoprops(gCoMat, prop='dissimilarity')[0][0]
homogeneity = graycoprops(gCoMat, prop='homogeneity')[0][0]
energy = graycoprops(gCoMat, prop='energy')[0][0]
correlation = graycoprops(gCoMat, prop='correlation')[0][0]
print("contrast: ",contrast)
print("dissimilarity: ",dissimilarity)
print("homogeneity: ",homogeneity)
print("energy: ",energy)
print("correlation: ",correlation)

"""##4. sift and GLCM on Full Dataset"""

images_sift = []
glcm=[]
labels = []
size = 128
sift = cv2.xfeatures2d.SIFT_create()
cataract=0
normal=0
for i, file in enumerate(file_names):
        image = cv2.imread(mypath+"/"+file,0)
        h,w=image.shape
        if(h>128 and w>128):
            image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)
            img_arr = np.array(image)
            gCoMat = graycomatrix(img_arr, [1], [0],256,symmetric=True, normed=True) # Co-occurance matrix
            contrast = graycoprops(gCoMat, prop='contrast')[0][0]
            dissimilarity = graycoprops(gCoMat, prop='dissimilarity')[0][0]
            homogeneity = graycoprops(gCoMat, prop='homogeneity')[0][0]
            energy = graycoprops(gCoMat, prop='energy')[0][0]
            correlation = graycoprops(gCoMat, prop='correlation')[0][0]
            keypoints, descriptors = sift.detectAndCompute(image,None)
            descriptors=np.array(descriptors)
            descriptors=descriptors.flatten()
            glcm.append([contrast,dissimilarity,homogeneity,energy,correlation])
            images_sift.append(descriptors[:2304])

            #print(descriptors.shape)
            if file_names[i][0] == "c":
                cataract+=1
                labels.append(1)
            if file_names[i][0] == "n":
                normal+=1
                labels.append(0)

print("Testing and validation split done!")

labels

images_sift=np.array(images_sift)
images_sift.shape

glcm=np.array(glcm)
images_sift_glcm=np.concatenate((images_sift,glcm),axis=1)
images_sift_glcm.shape

"""##5. Building ML Models"""

from sklearn import preprocessing
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

svm_rbf=svm.SVC(kernel='rbf',gamma=0.001,C=10)
svm_linear=svm.SVC(kernel='linear',gamma=0.001,C=10)
knn= KNeighborsClassifier(n_neighbors=2, metric='minkowski', p=2)
log = LogisticRegression(solver='liblinear')

model_names={"SVM RBF":svm_rbf,"SVM_linear":svm_linear,"k nearest neighbor":knn, "logistic regression":log}

def testing(model_name,X_train, X_test, y_train, y_test):
    model=model_names[model_name]
    model.fit(X_train,y_train)
    yhat = model.predict(X_test)
    # evaluate predictions
    acc = accuracy_score(y_test, yhat)
    print(model_name,'\tAccuracy: %.3f' % acc)
    print(confusion_matrix(y_test, yhat))
    print("\n\n")

def result(dataset):
    #Normalization
    #min_max_scaler = preprocessing.StandardScaler()
    #x_scaled = min_max_scaler.fit_transform(dataset)

    #panda dataframe
    df=pd.DataFrame(data=dataset)
    df['label']=labels
    df=df.sample(frac=1)
    X=df.drop(['label'], axis = 1)
    y=df['label']


    #Different model
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
    for model in ["SVM RBF","SVM_linear","k nearest neighbor","logistic regression"]:
        testing(model,X_train, X_test, y_train, y_test)

"""##Sift and GLCM Combined Features"""

print("Sift testing..........\n")
result(images_sift)

print("glcm testing..........\n")
result(glcm)

print("sift and glcm combined testing..........\n")
result(images_sift_glcm)

"""##6. Predicting"""

import pickle
from skimage.feature import graycomatrix, graycoprops
log_pickle_model = pickle.load(open("/content/drive/MyDrive/MBKM-CapstoneProject/log_model.sav", 'rb'))
sift = cv2.xfeatures2d.SIFT_create()
#min_max_scaler = preprocessing.MinMaxScaler()
size=128

def predict_new(image):
#     print(imagefile)
#     image_test = cv2.imread(mypath+"/"+imagefile,0)
    image_test = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    size = 128
    image_test = cv2.resize(image_test, (size, size), interpolation = cv2.INTER_AREA)
    glcm_test=[]
    images_sift_test=[]
    img_arr_test = np.array(image_test)
    gCoMat = graycomatrix(img_arr_test, [1], [0],256,symmetric=True, normed=True) # Co-occurance matrix
    contrast = graycoprops(gCoMat, prop='contrast')[0][0]
    dissimilarity = graycoprops(gCoMat, prop='dissimilarity')[0][0]
    homogeneity = graycoprops(gCoMat, prop='homogeneity')[0][0]
    energy = graycoprops(gCoMat, prop='energy')[0][0]
    correlation = graycoprops(gCoMat, prop='correlation')[0][0]
    keypoints, descriptors = sift.detectAndCompute(image_test,None)
    descriptors=np.array(descriptors)
    descriptors=descriptors.flatten()
    glcm_test.append([contrast,dissimilarity,homogeneity,energy,correlation])
    glcm_test=np.array(glcm_test)
    images_sift_test.append(descriptors[:2304])
    images_sift_test=np.array(images_sift_test)
    images_sift_glcm_test=np.concatenate((images_sift_test,glcm_test),axis=1)
#     if(imagefile[0]=='c'):
#         print("Actual: Cataract")
#     else:
#         print("Actual: Normal")
    if(loaded_model.predict(images_sift_glcm_test)==1):
        print("Predicted: Cataract")
    else:
        print("Predicted: Normal")
    print("******************************************************************")

filename = 'log_model.sav'
log = LogisticRegression(solver='liblinear')
while(True):
    df=pd.DataFrame(data=images_sift_glcm)
    df['label']=labels
    df=df.sample(frac=1)
    X=df.drop(['label'], axis = 1)
    y=df['label']
    #Different model
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
    log.fit(X_train,y_train)
    yhat = log.predict(X_test)
    # evaluate predictions
    acc = accuracy_score(y_test, yhat)
    print(acc*100)
    if(acc>0.97):
        pickle.dump(log, open(filename, 'wb'))
        break

# load the model from disk
import pickle
filename = 'log_model.sav'
loaded_model = pickle.load(open(filename, 'rb'))

img = cv2.imread('/content/drive/MyDrive/MBKM-CapstoneProject/case1.jpg')
if img is not None:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
else:
    print("Failed to load the image")

from google.colab.patches import cv2_imshow
cv2_imshow(img)
cv2.waitKey(0)

predict_new(img)